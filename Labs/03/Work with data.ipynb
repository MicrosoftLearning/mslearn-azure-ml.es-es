{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Trabajo con datos\n",
        "\n",
        "Los datos son la base sobre la que se construyen los modelos de Machine Learning. La administración centralizada de los datos en la nube y hacer que sean accesibles para los equipos de científicos de datos que ejecutan experimentos y modelos de entrenamiento en varias estaciones de trabajo y destinos de proceso es una parte importante de cualquier solución de ciencia de datos profesional.\n",
        "\n",
        "En este cuaderno, explorará dos objetos de Azure Machine Learning para trabajar con datos: *almacenes de datos* y *recursos de datos*.\n",
        "\n",
        "## Antes de comenzar\n",
        "\n",
        "Necesitará la versión más reciente del paquete **azureml-ai-ml** para ejecutar el código en este cuaderno. Ejecute la celda siguiente para comprobar que está instalada.\n",
        "\n",
        "> **Nota**:\n",
        "> Si el paquete **azure-ai-ml** no está instalado, ejecute `pip install azure-ai-ml` para instalarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789326586
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Conexión con su área de trabajo\n",
        "\n",
        "Con los paquetes de SDK necesarios instalados, ya está listo para conectarse al área de trabajo.\n",
        "\n",
        "Para conectarse a un espacio de trabajo, se necesitan parámetros de identificación: un id. de suscripción, un nombre de grupo de recursos y un nombre de espacio de trabajo. El nombre del grupo de recursos y el nombre del área de trabajo ya se rellenan automáticamente. Solo necesita el identificador de suscripción para completar el comando.\n",
        "\n",
        "Para buscar los parámetros necesarios, haga clic en la suscripción y el nombre del área de trabajo en la parte superior derecha de Studio. Se abrirá un panel a la derecha.\n",
        "\n",
        "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> Copie el identificador de suscripción y reemplace **YOUR-SUBSCRIPTION-ID** por el valor que copió. </p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Enumeración de los almacenes de datos\n",
        "\n",
        "Al crear el área de trabajo de Azure Machine Learning, también se crea una cuenta de Azure Storage. La cuenta de almacenamiento incluye blobs y almacenamiento de archivos y se conectan automáticamente con el área de trabajo como **almacenes de datos**. Puede enumerar todos los almacenes de datos conectados al área de trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666789343369
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Tenga en cuenta que `workspaceblobstore` se conecta al contenedor **azureml-blobstore-...** que ha explorado anteriormente. El `workspacefilestore` se conecta al  **código-...** de archivos compartidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creación de un almacén de datos\n",
        "\n",
        "Siempre que quiera conectar otro servicio de Almacenamiento de Azure con el área de trabajo de Azure Machine Learning, puede crear un almacén de datos. Tenga en cuenta que, al crear un almacén de datos, se crea la conexión entre el área de trabajo y el almacenamiento, no se crea el propio servicio de almacenamiento. \n",
        "\n",
        "Para crear un almacén de datos y conectarse a un almacenamiento (ya existente), deberá especificar:\n",
        "\n",
        "- La clase para indicar con qué tipo de servicio de almacenamiento desea conectarse. El ejemplo siguiente se conecta a un almacenamiento de blobs (`AzureBlobDatastore`).\n",
        "- `name`: nombre para mostrar del almacén de datos en el área de trabajo de Azure Machine Learning.\n",
        "- `description`: descripción opcional para proporcionar más información sobre el almacén de datos.\n",
        "- `account_name`: nombre de la cuenta de Azure Storage.\n",
        "- `container_name`: nombre del contenedor para almacenar blobs en la cuenta de Azure Storage.\n",
        "- `credentials`: proporcione el método de autenticación y las credenciales que se van a autenticar. En el ejemplo siguiente se usa una clave de cuenta.\n",
        "\n",
        "**Importante**: \n",
        "- Reemplace **YOUR-STORAGE-ACCOUNT-NAME** por el nombre de la cuenta de almacenamiento que se creó automáticamente. \n",
        "- Reemplace el **XXXX-XXXX** por `account_key` con la clave de cuenta de su cuenta de Azure Storage. \n",
        "\n",
        "Recuerde que puede recuperar la clave de la cuenta navegando al [Portal de Azure](https://portal.azure.com), vaya a su Cuenta de Almacenamiento, desde la pestaña **Claves de acceso**, copie el valor **Key** para la clave1 o la clave2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Vuelva a enumerar los almacenes de datos para comprobar que se ha creado un nuevo almacén de datos denominado `blob_training_data`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790805418
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Creación de recursos de datos\n",
        "\n",
        "Para apuntar a una carpeta o un recurso específicos en un almacén de datos, puede crear recursos de datos. Existen tres tipos de recursos de datos:\n",
        "\n",
        "- `URI_FILE` apunta a un archivo específico.\n",
        "- `URI_FOLDER` apunta a una carpeta específica.\n",
        "- `MLTABLE` apunta a un archivo MLTable que especifica cómo leer uno o varios archivos dentro de una carpeta.\n",
        "\n",
        "Creará los tres tipos de recursos de datos para experimentar las diferencias entre ellos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para crear un activo de datos `URI_FILE`, debe especificar una ruta que apunte a un archivo concreto. La ruta puede ser una ruta local o una ruta en la nube.\n",
        "\n",
        "En el ejemplo siguiente, creará un recurso de datos haciendo referencia a una ruta de acceso *local*. Para asegurarse de que los datos siempre están disponibles al trabajar con el área de trabajo de Azure Machine Learning, los archivos locales se cargarán automáticamente en el almacén de datos predeterminado. En este caso, el archivo `diabetes.csv` se cargará en la carpeta **LocalUpload** del almacén de datos **workspaceblobstore**. \n",
        "\n",
        "Para crear un recurso de datos a partir de un archivo local, ejecute la celda siguiente:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Para crear un recurso de datos `URI_FOLDER`, debe especificar una ruta que apunte a un archivo concreto. La ruta puede ser una ruta local o una ruta en la nube.\n",
        "\n",
        "En el ejemplo siguiente, creará un recurso de datos haciendo referencia a una ruta *en la nube*. La ruta de acceso aún no tiene que existir. La carpeta se creará cuando se carguen los datos en la ruta de acceso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790818340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "Para crear un recurso de datos `MLTable`, debe especificar una ruta que apunte a una carpeta que contenga un archivo MLTable. La ruta puede ser una ruta local o una ruta en la nube. \n",
        "\n",
        "En el ejemplo siguiente, creará un recurso de datos haciendo referencia a una ruta de acceso *local* que contiene un archivo MLTable y CSV. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Para comprobar que se han creado los nuevos recursos de datos, puede volver a enumerar todos los recursos de datos en el área de trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790835295
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "## Leer datos en el cuaderno\n",
        "\n",
        "Inicialmente, es posible que quiera trabajar con recursos de datos en cuadernos para explorar los datos y experimentar con los modelos de aprendizaje automático. Cualquier recurso de datos de tipo `URI_FILE` o `URI_FOLDER` se lee como se leen normalmente los datos. Por ejemplo, para leer un archivo CSV al que apunta un recurso de datos, puede utilizar la función de pandas `read_csv()`. \n",
        "\n",
        "Un recurso de datos de tipo `MLTable` ya está *leído* por el archivo **MLTable**, que especifica el esquema y cómo interpretar los datos. Dado que los datos ya se *leen*, puede convertir fácilmente un recurso de datos de MLTable en una trama de datos de Pandas. \n",
        "\n",
        "Necesitará instalar la biblioteca `mltable` (lo que ya ha hecho en el terminal). A continuación, puede convertir el recurso de datos en una trama de datos y visualizar los datos.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Utilizar datos en un trabajo\n",
        "\n",
        "Después de usar un cuaderno para la experimentación. Puede usar scripts para entrenar modelos de aprendizaje automático. Un script se puede ejecutar como un trabajo y, para cada trabajo, puede especificar entradas y salidas. \n",
        "\n",
        "Puede usar los **recursos de datos** o las **rutas** de acceso del almacén de datos como entradas o salidas de un trabajo. \n",
        "\n",
        "Las celdas siguientes crean el script **move-data.py** en la carpeta **src**. El script lee los datos de entrada con la función `read_csv()`. A continuación, el script almacena los datos como un archivo CSV en la ruta de acceso de salida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Para enviar un trabajo que ejecute el script **move-data.py**, ejecute la celda siguiente. \n",
        "\n",
        "El trabajo está configurado para utilizar el recurso de datos `diabetes-local`, que apunta al archivo local **diabetes.csv** como entrada. La salida es una ruta que apunta a una carpeta del nuevo almacén de datos `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790852019
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "my_path = './data/diabetes.csv'\n",
        "\n",
        "my_data = Data(\n",
        "    path=my_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"Data asset pointing to a local file, automatically uploaded to the default datastore\",\n",
        "    name=\"diabetes-local\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `URI_FOLDER` data asset, you have to specify a path that points to a specific folder. The path can be a local path or cloud path.\n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *cloud* path. The path doesn't have to exist yet. The folder will be created when data is uploaded to the path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666793449117
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "datastore_path = 'azureml://datastores/blob_training_data/paths/data-asset-path/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=datastore_path,\n",
        "    type=AssetTypes.URI_FOLDER,\n",
        "    description=\"Data asset pointing to data-asset-path folder in datastore\",\n",
        "    name=\"diabetes-datastore-path\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To create a `MLTable` data asset, you have to specify a path that points to a folder which contains a MLTable file. The path can be a local path or cloud path. \n",
        "\n",
        "In the example below, you'll create a data asset by referencing a *local* path which contains an MLTable and CSV file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790884342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "local_path = 'data/'\n",
        "\n",
        "my_data = Data(\n",
        "    path=local_path,\n",
        "    type=AssetTypes.MLTABLE,\n",
        "    description=\"MLTable pointing to diabetes.csv in data folder\",\n",
        "    name=\"diabetes-table\"\n",
        ")\n",
        "\n",
        "ml_client.data.create_or_update(my_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "To verify that the new data assets have been created, you can list all data assets in the workspace again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666790894246
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "datasets = ml_client.data.list()\n",
        "for ds_name in datasets:\n",
        "    print(ds_name.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Read data in notebook\n",
        "\n",
        "Initially, you may want to work with data assets in notebooks, to explore the data and experiment with machine learning models. Any `URI_FILE` or `URI_FOLDER` type data assets are read as you would normally read data. For example, to read a CSV file a data asset points to, you can use the pandas function `read_csv()`. \n",
        "\n",
        "A `MLTable` type data asset is already *read* by the **MLTable** file, which specifies the schema and how to interpret the data. Since the data is already *read*, you can easily convert a MLTable data asset to a pandas dataframe. \n",
        "\n",
        "You'll need to install the `mltable` library (which you did in the terminal). Then, you can convert the data asset to a dataframe and visualize the data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666792246101
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import mltable\n",
        "\n",
        "registered_data_asset = ml_client.data.get(name='diabetes-table', version=1)\n",
        "tbl = mltable.load(f\"azureml:/{registered_data_asset.id}\")\n",
        "df = tbl.to_pandas_dataframe()\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Use data in a job\n",
        "\n",
        "After using a notebook for experimentation. You can use scripts to train machine learning models. A script can be run as a job, and for each job you can specify inputs and outputs. \n",
        "\n",
        "You can use either **data assets** or **datastore paths** as inputs or outputs of a job. \n",
        "\n",
        "The cells below creates the **move-data.py** script in the **src** folder. The script reads the input data with the `read_csv()` function. The script then stores the data as a CSV file in the output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "%%writefile $script_folder/move-data.py\n",
        "# import libraries\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.input_data)\n",
        "\n",
        "    output_df = df.to_csv((Path(args.output_datastore) / \"diabetes.csv\"), index = False)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Count the rows and print the result\n",
        "    row_count = (len(df))\n",
        "    print('Analyzing {} rows of data'.format(row_count))\n",
        "    \n",
        "    return df\n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--input_data\", dest='input_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--output_datastore\", dest='output_datastore',\n",
        "                        type=str)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To submit a job that runs the **move-data.py** script, run the cell below. \n",
        "\n",
        "The job is configured to use the data asset `diabetes-local`, pointing to the local **diabetes.csv** file as input. The output is a path pointing to a folder in the new datastore `blob_training_data`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1666794414231
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from azure.ai.ml import Input, Output\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "from azure.ai.ml import command\n",
        "\n",
        "# configure input and output\n",
        "my_job_inputs = {\n",
        "    \"local_data\": Input(type=AssetTypes.URI_FILE, path=\"azureml:diabetes-local:1\")\n",
        "}\n",
        "\n",
        "my_job_outputs = {\n",
        "    \"datastore_data\": Output(type=AssetTypes.URI_FOLDER, path=\"azureml://datastores/blob_training_data/paths/datastore-path\")\n",
        "}\n",
        "\n",
        "# configure job\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python move-data.py --input_data ${{inputs.local_data}} --output_datastore ${{outputs.datastore_data}}\",\n",
        "    inputs=my_job_inputs,\n",
        "    outputs=my_job_outputs,\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"move-diabetes-data\",\n",
        "    experiment_name=\"move-diabetes-data\"\n",
        ")\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}